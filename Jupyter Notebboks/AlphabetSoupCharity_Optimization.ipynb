{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd\n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df = application_df.drop(columns=['EIN', 'NAME'])\n",
    "\n",
    "# Display the first few rows of the dataframe to confirm the drop\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "unique_values = application_df.nunique()\n",
    "# Display the unique values for each column\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Determine the number of unique values in each column.\n",
    "application_df.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLICATION_TYPE\n",
      "T3     27037\n",
      "T4      1542\n",
      "T6      1216\n",
      "T5      1173\n",
      "T19     1065\n",
      "T8       737\n",
      "T7       725\n",
      "T10      528\n",
      "T9       156\n",
      "T13       66\n",
      "T12       27\n",
      "T2        16\n",
      "T25        3\n",
      "T14        3\n",
      "T29        2\n",
      "T15        2\n",
      "T17        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts to identify and replace with \"Other\"\n",
    "application_type_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
    "print(application_type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "cutoff = 528\n",
    "application_types_to_replace = application_df['APPLICATION_TYPE'].value_counts()\n",
    "application_types_to_replace = application_types_to_replace[application_types_to_replace < cutoff].index.tolist()\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure replacement was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION\n",
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "         ...  \n",
      "C4120        1\n",
      "C8210        1\n",
      "C2561        1\n",
      "C4500        1\n",
      "C2150        1\n",
      "Name: count, Length: 71, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts to identify and replace with \"Other\"\n",
    "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
    "print(classification_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION\n",
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "C7000      777\n",
      "C1700      287\n",
      "C4000      194\n",
      "C5000      116\n",
      "C1270      114\n",
      "C2700      104\n",
      "C2800       95\n",
      "C7100       75\n",
      "C1300       58\n",
      "C1280       50\n",
      "C1230       36\n",
      "C1400       34\n",
      "C7200       32\n",
      "C2300       32\n",
      "C1240       30\n",
      "C8000       20\n",
      "C7120       18\n",
      "C1500       16\n",
      "C1800       15\n",
      "C6000       15\n",
      "C1250       14\n",
      "C8200       11\n",
      "C1238       10\n",
      "C1278       10\n",
      "C1235        9\n",
      "C1237        9\n",
      "C7210        7\n",
      "C2400        6\n",
      "C1720        6\n",
      "C4100        6\n",
      "C1257        5\n",
      "C1600        5\n",
      "C1260        3\n",
      "C2710        3\n",
      "C0           3\n",
      "C3200        2\n",
      "C1234        2\n",
      "C1246        2\n",
      "C1267        2\n",
      "C1256        2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
    "classification_counts_more_than_one = classification_counts[classification_counts > 1]\n",
    "print(classification_counts_more_than_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "cutoff = 1883 \n",
    "classifications_to_replace = classification_counts[classification_counts < cutoff].index.tolist()\n",
    "\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "\n",
    "# Check to make sure replacement was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                       0   \n",
       "1       1   108590              1                       0   \n",
       "2       1     5000              0                       0   \n",
       "3       1     6692              1                       0   \n",
       "4       1   142590              1                       0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                     1                     0                    0   \n",
       "1                     0                     0                    1   \n",
       "2                     0                     0                    0   \n",
       "3                     0                     0                    1   \n",
       "4                     0                     0                    1   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                    0                    0                    0  ...   \n",
       "1                    0                    0                    0  ...   \n",
       "2                    0                    1                    0  ...   \n",
       "3                    0                    0                    0  ...   \n",
       "4                    0                    0                    0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                  0                       0                         0   \n",
       "1                  1                       0                         0   \n",
       "2                  0                       0                         0   \n",
       "3                  0                       1                         0   \n",
       "4                  0                       0                         1   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                   0                 0                       0   \n",
       "1                   0                 0                       0   \n",
       "2                   0                 0                       0   \n",
       "3                   0                 0                       0   \n",
       "4                   0                 0                       0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                0                  0                         1   \n",
       "1                0                  0                         1   \n",
       "2                0                  0                         1   \n",
       "3                0                  0                         1   \n",
       "4                0                  0                         1   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "application_df_dummies = pd.get_dummies(application_df)\n",
    "# Convert Boolean columns to integers (1 and 0)\n",
    "application_df_dummies = application_df_dummies * 1\n",
    "\n",
    "# Display the first few rows of the new DataFrame to verify the conversio\n",
    "application_df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_df_dummies['IS_SUCCESSFUL'].values\n",
    "X = application_df_dummies.drop(columns='IS_SUCCESSFUL').values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,520</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">465</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m3,520\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m2,430\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m465\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m16\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,431</span> (25.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,431\u001b[0m (25.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,431</span> (25.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,431\u001b[0m (25.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Second attempt\n",
    "# Define the model - deep neural net\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# Input layer and first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=80, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=30, activation='relu'))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=15, activation='relu'))\n",
    "\n",
    "# Dropout layer for regularization\n",
    "nn.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,520</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">465</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m3,520\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m2,430\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m465\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m16\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,431</span> (25.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,431\u001b[0m (25.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,431</span> (25.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,431\u001b[0m (25.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452us/step - accuracy: 0.6896 - loss: 0.6036 - val_accuracy: 0.7345 - val_loss: 0.5515\n",
      "Epoch 2/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7249 - loss: 0.5633 - val_accuracy: 0.7314 - val_loss: 0.5507\n",
      "Epoch 3/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7234 - loss: 0.5600 - val_accuracy: 0.7337 - val_loss: 0.5488\n",
      "Epoch 4/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7254 - loss: 0.5572 - val_accuracy: 0.7304 - val_loss: 0.5506\n",
      "Epoch 5/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.7264 - loss: 0.5547 - val_accuracy: 0.7308 - val_loss: 0.5488\n",
      "Epoch 6/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7259 - loss: 0.5530 - val_accuracy: 0.7326 - val_loss: 0.5485\n",
      "Epoch 7/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.7264 - loss: 0.5537 - val_accuracy: 0.7308 - val_loss: 0.5475\n",
      "Epoch 8/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7293 - loss: 0.5528 - val_accuracy: 0.7312 - val_loss: 0.5474\n",
      "Epoch 9/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7265 - loss: 0.5542 - val_accuracy: 0.7364 - val_loss: 0.5465\n",
      "Epoch 10/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7276 - loss: 0.5522 - val_accuracy: 0.7326 - val_loss: 0.5481\n",
      "Epoch 11/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.7284 - loss: 0.5530 - val_accuracy: 0.7320 - val_loss: 0.5478\n",
      "Epoch 12/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.7287 - loss: 0.5516 - val_accuracy: 0.7314 - val_loss: 0.5469\n",
      "Epoch 13/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - accuracy: 0.7305 - loss: 0.5512 - val_accuracy: 0.7337 - val_loss: 0.5464\n",
      "Epoch 14/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7310 - loss: 0.5491 - val_accuracy: 0.7326 - val_loss: 0.5479\n",
      "Epoch 15/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7294 - loss: 0.5501 - val_accuracy: 0.7331 - val_loss: 0.5478\n",
      "Epoch 16/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7313 - loss: 0.5507 - val_accuracy: 0.7333 - val_loss: 0.5476\n",
      "Epoch 17/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7288 - loss: 0.5503 - val_accuracy: 0.7329 - val_loss: 0.5477\n",
      "Epoch 18/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.7289 - loss: 0.5476 - val_accuracy: 0.7326 - val_loss: 0.5486\n",
      "Epoch 19/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7297 - loss: 0.5491 - val_accuracy: 0.7308 - val_loss: 0.5487\n",
      "Epoch 20/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7300 - loss: 0.5496 - val_accuracy: 0.7310 - val_loss: 0.5485\n",
      "Epoch 21/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7273 - loss: 0.5501 - val_accuracy: 0.7359 - val_loss: 0.5486\n",
      "Epoch 22/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7315 - loss: 0.5488 - val_accuracy: 0.7353 - val_loss: 0.5488\n",
      "Epoch 23/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.7299 - loss: 0.5479 - val_accuracy: 0.7359 - val_loss: 0.5470\n",
      "Epoch 24/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7310 - loss: 0.5480 - val_accuracy: 0.7351 - val_loss: 0.5472\n",
      "Epoch 25/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7313 - loss: 0.5467 - val_accuracy: 0.7312 - val_loss: 0.5488\n",
      "Epoch 26/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7327 - loss: 0.5460 - val_accuracy: 0.7312 - val_loss: 0.5472\n",
      "Epoch 27/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7334 - loss: 0.5469 - val_accuracy: 0.7364 - val_loss: 0.5475\n",
      "Epoch 28/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7325 - loss: 0.5459 - val_accuracy: 0.7316 - val_loss: 0.5478\n",
      "Epoch 29/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7305 - loss: 0.5466 - val_accuracy: 0.7351 - val_loss: 0.5477\n",
      "Epoch 30/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.7357 - loss: 0.5476 - val_accuracy: 0.7351 - val_loss: 0.5466\n",
      "Epoch 31/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.7308 - loss: 0.5469 - val_accuracy: 0.7353 - val_loss: 0.5481\n",
      "Epoch 32/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7334 - loss: 0.5455 - val_accuracy: 0.7306 - val_loss: 0.5468\n",
      "Epoch 33/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7318 - loss: 0.5454 - val_accuracy: 0.7357 - val_loss: 0.5466\n",
      "Epoch 34/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7333 - loss: 0.5454 - val_accuracy: 0.7368 - val_loss: 0.5465\n",
      "Epoch 35/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7346 - loss: 0.5432 - val_accuracy: 0.7304 - val_loss: 0.5479\n",
      "Epoch 36/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7326 - loss: 0.5455 - val_accuracy: 0.7306 - val_loss: 0.5487\n",
      "Epoch 37/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7334 - loss: 0.5446 - val_accuracy: 0.7362 - val_loss: 0.5472\n",
      "Epoch 38/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7333 - loss: 0.5439 - val_accuracy: 0.7355 - val_loss: 0.5478\n",
      "Epoch 39/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7345 - loss: 0.5438 - val_accuracy: 0.7366 - val_loss: 0.5477\n",
      "Epoch 40/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7331 - loss: 0.5427 - val_accuracy: 0.7380 - val_loss: 0.5471\n",
      "Epoch 41/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7343 - loss: 0.5453 - val_accuracy: 0.7347 - val_loss: 0.5493\n",
      "Epoch 42/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7341 - loss: 0.5445 - val_accuracy: 0.7357 - val_loss: 0.5480\n",
      "Epoch 43/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7352 - loss: 0.5439 - val_accuracy: 0.7359 - val_loss: 0.5484\n",
      "Epoch 44/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7342 - loss: 0.5420 - val_accuracy: 0.7361 - val_loss: 0.5483\n",
      "Epoch 45/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7352 - loss: 0.5432 - val_accuracy: 0.7378 - val_loss: 0.5490\n",
      "Epoch 46/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.7352 - loss: 0.5424 - val_accuracy: 0.7386 - val_loss: 0.5472\n",
      "Epoch 47/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7339 - loss: 0.5442 - val_accuracy: 0.7353 - val_loss: 0.5489\n",
      "Epoch 48/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7334 - loss: 0.5435 - val_accuracy: 0.7388 - val_loss: 0.5478\n",
      "Epoch 49/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7358 - loss: 0.5425 - val_accuracy: 0.7376 - val_loss: 0.5483\n",
      "Epoch 50/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.7344 - loss: 0.5440 - val_accuracy: 0.7366 - val_loss: 0.5477\n",
      "Epoch 51/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.7345 - loss: 0.5434 - val_accuracy: 0.7366 - val_loss: 0.5477\n",
      "Epoch 52/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.7330 - loss: 0.5445 - val_accuracy: 0.7380 - val_loss: 0.5472\n",
      "Epoch 53/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.7355 - loss: 0.5422 - val_accuracy: 0.7378 - val_loss: 0.5479\n",
      "Epoch 54/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - accuracy: 0.7348 - loss: 0.5419 - val_accuracy: 0.7374 - val_loss: 0.5465\n",
      "Epoch 55/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.7348 - loss: 0.5435 - val_accuracy: 0.7320 - val_loss: 0.5498\n",
      "Epoch 56/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7336 - loss: 0.5435 - val_accuracy: 0.7370 - val_loss: 0.5491\n",
      "Epoch 57/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - accuracy: 0.7335 - loss: 0.5416 - val_accuracy: 0.7370 - val_loss: 0.5493\n",
      "Epoch 58/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.7346 - loss: 0.5423 - val_accuracy: 0.7361 - val_loss: 0.5493\n",
      "Epoch 59/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - accuracy: 0.7350 - loss: 0.5436 - val_accuracy: 0.7386 - val_loss: 0.5490\n",
      "Epoch 60/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7355 - loss: 0.5435 - val_accuracy: 0.7368 - val_loss: 0.5493\n",
      "Epoch 61/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7353 - loss: 0.5422 - val_accuracy: 0.7374 - val_loss: 0.5495\n",
      "Epoch 62/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7328 - loss: 0.5427 - val_accuracy: 0.7366 - val_loss: 0.5499\n",
      "Epoch 63/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.7347 - loss: 0.5421 - val_accuracy: 0.7366 - val_loss: 0.5488\n",
      "Epoch 64/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.7350 - loss: 0.5410 - val_accuracy: 0.7372 - val_loss: 0.5488\n",
      "Epoch 65/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7348 - loss: 0.5420 - val_accuracy: 0.7382 - val_loss: 0.5499\n",
      "Epoch 66/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7361 - loss: 0.5409 - val_accuracy: 0.7368 - val_loss: 0.5501\n",
      "Epoch 67/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7346 - loss: 0.5410 - val_accuracy: 0.7374 - val_loss: 0.5510\n",
      "Epoch 68/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7344 - loss: 0.5423 - val_accuracy: 0.7326 - val_loss: 0.5493\n",
      "Epoch 69/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7332 - loss: 0.5423 - val_accuracy: 0.7359 - val_loss: 0.5515\n",
      "Epoch 70/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7338 - loss: 0.5419 - val_accuracy: 0.7362 - val_loss: 0.5504\n",
      "Epoch 71/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7344 - loss: 0.5431 - val_accuracy: 0.7359 - val_loss: 0.5515\n",
      "Epoch 72/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.7345 - loss: 0.5420 - val_accuracy: 0.7376 - val_loss: 0.5494\n",
      "Epoch 73/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.7345 - loss: 0.5412 - val_accuracy: 0.7372 - val_loss: 0.5499\n",
      "Epoch 74/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7353 - loss: 0.5422 - val_accuracy: 0.7361 - val_loss: 0.5503\n",
      "Epoch 75/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7340 - loss: 0.5411 - val_accuracy: 0.7304 - val_loss: 0.5512\n",
      "Epoch 76/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7325 - loss: 0.5429 - val_accuracy: 0.7318 - val_loss: 0.5514\n",
      "Epoch 77/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7347 - loss: 0.5414 - val_accuracy: 0.7353 - val_loss: 0.5522\n",
      "Epoch 78/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7342 - loss: 0.5399 - val_accuracy: 0.7353 - val_loss: 0.5505\n",
      "Epoch 79/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.7341 - loss: 0.5420 - val_accuracy: 0.7361 - val_loss: 0.5522\n",
      "Epoch 80/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7366 - loss: 0.5394 - val_accuracy: 0.7349 - val_loss: 0.5507\n",
      "Epoch 81/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.7367 - loss: 0.5401 - val_accuracy: 0.7378 - val_loss: 0.5517\n",
      "Epoch 82/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7349 - loss: 0.5412 - val_accuracy: 0.7355 - val_loss: 0.5530\n",
      "Epoch 83/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7330 - loss: 0.5408 - val_accuracy: 0.7355 - val_loss: 0.5501\n",
      "Epoch 84/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.7356 - loss: 0.5406 - val_accuracy: 0.7368 - val_loss: 0.5512\n",
      "Epoch 85/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7354 - loss: 0.5398 - val_accuracy: 0.7351 - val_loss: 0.5504\n",
      "Epoch 86/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7357 - loss: 0.5415 - val_accuracy: 0.7357 - val_loss: 0.5517\n",
      "Epoch 87/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7350 - loss: 0.5411 - val_accuracy: 0.7361 - val_loss: 0.5548\n",
      "Epoch 88/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7363 - loss: 0.5400 - val_accuracy: 0.7359 - val_loss: 0.5525\n",
      "Epoch 89/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7353 - loss: 0.5389 - val_accuracy: 0.7361 - val_loss: 0.5528\n",
      "Epoch 90/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7340 - loss: 0.5386 - val_accuracy: 0.7357 - val_loss: 0.5546\n",
      "Epoch 91/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7354 - loss: 0.5399 - val_accuracy: 0.7368 - val_loss: 0.5538\n",
      "Epoch 92/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7347 - loss: 0.5392 - val_accuracy: 0.7370 - val_loss: 0.5531\n",
      "Epoch 93/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7362 - loss: 0.5403 - val_accuracy: 0.7376 - val_loss: 0.5523\n",
      "Epoch 94/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7323 - loss: 0.5413 - val_accuracy: 0.7361 - val_loss: 0.5531\n",
      "Epoch 95/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7357 - loss: 0.5408 - val_accuracy: 0.7320 - val_loss: 0.5531\n",
      "Epoch 96/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7338 - loss: 0.5412 - val_accuracy: 0.7364 - val_loss: 0.5535\n",
      "Epoch 97/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7359 - loss: 0.5402 - val_accuracy: 0.7353 - val_loss: 0.5537\n",
      "Epoch 98/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7357 - loss: 0.5393 - val_accuracy: 0.7359 - val_loss: 0.5557\n",
      "Epoch 99/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7386 - loss: 0.5395 - val_accuracy: 0.7349 - val_loss: 0.5557\n",
      "Epoch 100/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7361 - loss: 0.5405 - val_accuracy: 0.7368 - val_loss: 0.5522\n",
      "Epoch 101/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7344 - loss: 0.5390 - val_accuracy: 0.7378 - val_loss: 0.5542\n",
      "Epoch 102/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.7362 - loss: 0.5386 - val_accuracy: 0.7378 - val_loss: 0.5541\n",
      "Epoch 103/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - accuracy: 0.7361 - loss: 0.5401 - val_accuracy: 0.7366 - val_loss: 0.5519\n",
      "Epoch 104/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7379 - loss: 0.5384 - val_accuracy: 0.7366 - val_loss: 0.5532\n",
      "Epoch 105/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7351 - loss: 0.5389 - val_accuracy: 0.7364 - val_loss: 0.5532\n",
      "Epoch 106/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7361 - loss: 0.5391 - val_accuracy: 0.7368 - val_loss: 0.5529\n",
      "Epoch 107/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.7361 - loss: 0.5397 - val_accuracy: 0.7362 - val_loss: 0.5545\n",
      "Epoch 108/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7357 - loss: 0.5378 - val_accuracy: 0.7351 - val_loss: 0.5557\n",
      "Epoch 109/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.7357 - loss: 0.5390 - val_accuracy: 0.7361 - val_loss: 0.5562\n",
      "Epoch 110/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.7361 - loss: 0.5384 - val_accuracy: 0.7366 - val_loss: 0.5517\n",
      "Epoch 111/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7366 - loss: 0.5388 - val_accuracy: 0.7362 - val_loss: 0.5545\n",
      "Epoch 112/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.7350 - loss: 0.5385 - val_accuracy: 0.7355 - val_loss: 0.5571\n",
      "Epoch 113/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7353 - loss: 0.5412 - val_accuracy: 0.7366 - val_loss: 0.5563\n",
      "Epoch 114/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.7366 - loss: 0.5388 - val_accuracy: 0.7359 - val_loss: 0.5567\n",
      "Epoch 115/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7346 - loss: 0.5398 - val_accuracy: 0.7366 - val_loss: 0.5553\n",
      "Epoch 116/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.7351 - loss: 0.5384 - val_accuracy: 0.7351 - val_loss: 0.5553\n",
      "Epoch 117/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7361 - loss: 0.5397 - val_accuracy: 0.7355 - val_loss: 0.5558\n",
      "Epoch 118/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.7358 - loss: 0.5392 - val_accuracy: 0.7370 - val_loss: 0.5548\n",
      "Epoch 119/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7350 - loss: 0.5397 - val_accuracy: 0.7361 - val_loss: 0.5564\n",
      "Epoch 120/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.7359 - loss: 0.5391 - val_accuracy: 0.7339 - val_loss: 0.5575\n",
      "Epoch 121/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.7358 - loss: 0.5376 - val_accuracy: 0.7357 - val_loss: 0.5574\n",
      "Epoch 122/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7355 - loss: 0.5395 - val_accuracy: 0.7349 - val_loss: 0.5589\n",
      "Epoch 123/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.7367 - loss: 0.5376 - val_accuracy: 0.7362 - val_loss: 0.5571\n",
      "Epoch 124/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7390 - loss: 0.5375 - val_accuracy: 0.7361 - val_loss: 0.5549\n",
      "Epoch 125/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.7366 - loss: 0.5383 - val_accuracy: 0.7364 - val_loss: 0.5573\n",
      "Epoch 126/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.7365 - loss: 0.5392 - val_accuracy: 0.7366 - val_loss: 0.5570\n",
      "Epoch 127/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.7353 - loss: 0.5387 - val_accuracy: 0.7361 - val_loss: 0.5585\n",
      "Epoch 128/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7377 - loss: 0.5386 - val_accuracy: 0.7355 - val_loss: 0.5548\n",
      "Epoch 129/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.7379 - loss: 0.5375 - val_accuracy: 0.7359 - val_loss: 0.5563\n",
      "Epoch 130/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.7361 - loss: 0.5383 - val_accuracy: 0.7372 - val_loss: 0.5573\n",
      "Epoch 131/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7366 - loss: 0.5390 - val_accuracy: 0.7370 - val_loss: 0.5550\n",
      "Epoch 132/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7391 - loss: 0.5370 - val_accuracy: 0.7364 - val_loss: 0.5615\n",
      "Epoch 133/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.7362 - loss: 0.5388 - val_accuracy: 0.7351 - val_loss: 0.5632\n",
      "Epoch 134/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7354 - loss: 0.5388 - val_accuracy: 0.7370 - val_loss: 0.5574\n",
      "Epoch 135/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7360 - loss: 0.5381 - val_accuracy: 0.7353 - val_loss: 0.5591\n",
      "Epoch 136/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7372 - loss: 0.5377 - val_accuracy: 0.7355 - val_loss: 0.5632\n",
      "Epoch 137/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7362 - loss: 0.5393 - val_accuracy: 0.7353 - val_loss: 0.5571\n",
      "Epoch 138/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7360 - loss: 0.5382 - val_accuracy: 0.7355 - val_loss: 0.5590\n",
      "Epoch 139/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.7374 - loss: 0.5393 - val_accuracy: 0.7347 - val_loss: 0.5572\n",
      "Epoch 140/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.7376 - loss: 0.5378 - val_accuracy: 0.7345 - val_loss: 0.5577\n",
      "Epoch 141/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.7375 - loss: 0.5378 - val_accuracy: 0.7345 - val_loss: 0.5599\n",
      "Epoch 142/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.7375 - loss: 0.5394 - val_accuracy: 0.7353 - val_loss: 0.5581\n",
      "Epoch 143/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7355 - loss: 0.5388 - val_accuracy: 0.7362 - val_loss: 0.5581\n",
      "Epoch 144/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.7381 - loss: 0.5388 - val_accuracy: 0.7357 - val_loss: 0.5579\n",
      "Epoch 145/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7355 - loss: 0.5383 - val_accuracy: 0.7357 - val_loss: 0.5603\n",
      "Epoch 146/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.7368 - loss: 0.5367 - val_accuracy: 0.7353 - val_loss: 0.5593\n",
      "Epoch 147/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.7372 - loss: 0.5365 - val_accuracy: 0.7349 - val_loss: 0.5629\n",
      "Epoch 148/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.7360 - loss: 0.5384 - val_accuracy: 0.7351 - val_loss: 0.5624\n",
      "Epoch 149/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.7366 - loss: 0.5375 - val_accuracy: 0.7345 - val_loss: 0.5598\n",
      "Epoch 150/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7367 - loss: 0.5377 - val_accuracy: 0.7343 - val_loss: 0.5590\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=150, batch_size=32, verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 252us/step - accuracy: 0.7290 - loss: 0.5733\n",
      "Loss: 0.5732925534248352, Accuracy: 0.7289795875549316\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second Attempt Analysis**\n",
    "\n",
    "**Architecture:**\n",
    "\n",
    "Input Features: 43 (including all numeric and one-hot encoded categorical variables).\n",
    "Hidden Layers:\n",
    "Layer 1: 80 neurons with ReLU activation.\n",
    "Layer 2: 30 neurons with ReLU activation.\n",
    "Layer 3: 15 neurons with ReLU activation.\n",
    "Dropout Layer: Regularization with a rate of 0.2 to prevent overfitting.\n",
    "Output Layer: 1 neuron with sigmoid activation (for binary classification).\n",
    "\n",
    "**Results:**\n",
    "\n",
    "Accuracy: 72.90%\n",
    "Loss: 0.5733\n",
    "\n",
    "**Key Observations:**\n",
    "\n",
    "The accuracy improved slightly compared to the initial attempt (72.65%), likely due to the deeper architecture and regularization.\n",
    "The loss increased slightly to 0.5733, which may indicate increased model complexity and potential overfitting despite the dropout layer.\n",
    "The model demonstrates better generalization but shows diminishing returns in accuracy improvements.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Experiment with additional optimizations, such as increasing neurons in the hidden layers or adjusting the dropout rate.\n",
    "Consider tuning hyperparameters, such as the learning rate or batch size, to refine performance further.\n",
    "Evaluate whether additional hidden layers or advanced regularization methods (e.g., L2 regularization) can improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"H5/AlphabetSoupCharity_Attempt_2.h5\")\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,530</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">465</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m4,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m5,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m1,530\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m465\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m16\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,461</span> (44.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,461\u001b[0m (44.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,461</span> (44.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,461\u001b[0m (44.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Third Attempt\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# Input layer and first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=100, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=30, activation='relu'))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=15, activation='relu'))\n",
    "\n",
    "# Dropout layer\n",
    "nn.add(tf.keras.layers.Dropout(0.1))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,530</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">465</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m4,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m5,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m1,530\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m465\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m16\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,461</span> (44.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,461\u001b[0m (44.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,461</span> (44.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,461\u001b[0m (44.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462us/step - accuracy: 0.6972 - loss: 0.5979 - val_accuracy: 0.7298 - val_loss: 0.5512\n",
      "Epoch 2/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7221 - loss: 0.5611 - val_accuracy: 0.7304 - val_loss: 0.5483\n",
      "Epoch 3/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7266 - loss: 0.5576 - val_accuracy: 0.7300 - val_loss: 0.5478\n",
      "Epoch 4/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7274 - loss: 0.5538 - val_accuracy: 0.7310 - val_loss: 0.5470\n",
      "Epoch 5/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.7268 - loss: 0.5520 - val_accuracy: 0.7298 - val_loss: 0.5474\n",
      "Epoch 6/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7274 - loss: 0.5519 - val_accuracy: 0.7306 - val_loss: 0.5483\n",
      "Epoch 7/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7265 - loss: 0.5497 - val_accuracy: 0.7310 - val_loss: 0.5471\n",
      "Epoch 8/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7296 - loss: 0.5496 - val_accuracy: 0.7361 - val_loss: 0.5467\n",
      "Epoch 9/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7289 - loss: 0.5500 - val_accuracy: 0.7312 - val_loss: 0.5483\n",
      "Epoch 10/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - accuracy: 0.7303 - loss: 0.5496 - val_accuracy: 0.7368 - val_loss: 0.5482\n",
      "Epoch 11/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7294 - loss: 0.5481 - val_accuracy: 0.7374 - val_loss: 0.5477\n",
      "Epoch 12/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7304 - loss: 0.5496 - val_accuracy: 0.7335 - val_loss: 0.5489\n",
      "Epoch 13/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7311 - loss: 0.5486 - val_accuracy: 0.7329 - val_loss: 0.5470\n",
      "Epoch 14/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7309 - loss: 0.5480 - val_accuracy: 0.7366 - val_loss: 0.5461\n",
      "Epoch 15/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7314 - loss: 0.5489 - val_accuracy: 0.7382 - val_loss: 0.5462\n",
      "Epoch 16/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7325 - loss: 0.5456 - val_accuracy: 0.7384 - val_loss: 0.5469\n",
      "Epoch 17/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.7337 - loss: 0.5461 - val_accuracy: 0.7382 - val_loss: 0.5462\n",
      "Epoch 18/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7349 - loss: 0.5456 - val_accuracy: 0.7368 - val_loss: 0.5462\n",
      "Epoch 19/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7323 - loss: 0.5455 - val_accuracy: 0.7333 - val_loss: 0.5467\n",
      "Epoch 20/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7316 - loss: 0.5446 - val_accuracy: 0.7380 - val_loss: 0.5485\n",
      "Epoch 21/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7322 - loss: 0.5450 - val_accuracy: 0.7328 - val_loss: 0.5477\n",
      "Epoch 22/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7330 - loss: 0.5448 - val_accuracy: 0.7366 - val_loss: 0.5454\n",
      "Epoch 23/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7338 - loss: 0.5456 - val_accuracy: 0.7326 - val_loss: 0.5469\n",
      "Epoch 24/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7324 - loss: 0.5449 - val_accuracy: 0.7359 - val_loss: 0.5465\n",
      "Epoch 25/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7322 - loss: 0.5453 - val_accuracy: 0.7318 - val_loss: 0.5453\n",
      "Epoch 26/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7340 - loss: 0.5440 - val_accuracy: 0.7345 - val_loss: 0.5484\n",
      "Epoch 27/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7337 - loss: 0.5450 - val_accuracy: 0.7335 - val_loss: 0.5459\n",
      "Epoch 28/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7328 - loss: 0.5434 - val_accuracy: 0.7370 - val_loss: 0.5457\n",
      "Epoch 29/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7369 - loss: 0.5422 - val_accuracy: 0.7376 - val_loss: 0.5477\n",
      "Epoch 30/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7350 - loss: 0.5437 - val_accuracy: 0.7361 - val_loss: 0.5462\n",
      "Epoch 31/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7336 - loss: 0.5426 - val_accuracy: 0.7368 - val_loss: 0.5476\n",
      "Epoch 32/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7358 - loss: 0.5441 - val_accuracy: 0.7362 - val_loss: 0.5468\n",
      "Epoch 33/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.7362 - loss: 0.5429 - val_accuracy: 0.7390 - val_loss: 0.5480\n",
      "Epoch 34/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7359 - loss: 0.5440 - val_accuracy: 0.7370 - val_loss: 0.5477\n",
      "Epoch 35/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7370 - loss: 0.5431 - val_accuracy: 0.7368 - val_loss: 0.5462\n",
      "Epoch 36/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7370 - loss: 0.5421 - val_accuracy: 0.7374 - val_loss: 0.5468\n",
      "Epoch 37/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7350 - loss: 0.5420 - val_accuracy: 0.7376 - val_loss: 0.5458\n",
      "Epoch 38/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7366 - loss: 0.5424 - val_accuracy: 0.7374 - val_loss: 0.5467\n",
      "Epoch 39/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7356 - loss: 0.5432 - val_accuracy: 0.7368 - val_loss: 0.5484\n",
      "Epoch 40/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7357 - loss: 0.5417 - val_accuracy: 0.7320 - val_loss: 0.5473\n",
      "Epoch 41/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7353 - loss: 0.5408 - val_accuracy: 0.7368 - val_loss: 0.5469\n",
      "Epoch 42/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7365 - loss: 0.5408 - val_accuracy: 0.7322 - val_loss: 0.5478\n",
      "Epoch 43/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7368 - loss: 0.5408 - val_accuracy: 0.7372 - val_loss: 0.5467\n",
      "Epoch 44/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.7362 - loss: 0.5404 - val_accuracy: 0.7361 - val_loss: 0.5476\n",
      "Epoch 45/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7363 - loss: 0.5401 - val_accuracy: 0.7374 - val_loss: 0.5479\n",
      "Epoch 46/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7377 - loss: 0.5397 - val_accuracy: 0.7368 - val_loss: 0.5473\n",
      "Epoch 47/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7377 - loss: 0.5399 - val_accuracy: 0.7374 - val_loss: 0.5466\n",
      "Epoch 48/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7366 - loss: 0.5407 - val_accuracy: 0.7357 - val_loss: 0.5488\n",
      "Epoch 49/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7368 - loss: 0.5403 - val_accuracy: 0.7366 - val_loss: 0.5493\n",
      "Epoch 50/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.7356 - loss: 0.5398 - val_accuracy: 0.7378 - val_loss: 0.5471\n",
      "Epoch 51/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7360 - loss: 0.5395 - val_accuracy: 0.7372 - val_loss: 0.5478\n",
      "Epoch 52/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7394 - loss: 0.5383 - val_accuracy: 0.7382 - val_loss: 0.5496\n",
      "Epoch 53/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7377 - loss: 0.5405 - val_accuracy: 0.7364 - val_loss: 0.5494\n",
      "Epoch 54/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7379 - loss: 0.5388 - val_accuracy: 0.7368 - val_loss: 0.5492\n",
      "Epoch 55/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7373 - loss: 0.5397 - val_accuracy: 0.7368 - val_loss: 0.5507\n",
      "Epoch 56/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7366 - loss: 0.5386 - val_accuracy: 0.7368 - val_loss: 0.5500\n",
      "Epoch 57/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7374 - loss: 0.5385 - val_accuracy: 0.7355 - val_loss: 0.5549\n",
      "Epoch 58/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7384 - loss: 0.5375 - val_accuracy: 0.7386 - val_loss: 0.5493\n",
      "Epoch 59/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7364 - loss: 0.5387 - val_accuracy: 0.7368 - val_loss: 0.5495\n",
      "Epoch 60/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7372 - loss: 0.5385 - val_accuracy: 0.7357 - val_loss: 0.5538\n",
      "Epoch 61/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7379 - loss: 0.5385 - val_accuracy: 0.7376 - val_loss: 0.5517\n",
      "Epoch 62/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7388 - loss: 0.5375 - val_accuracy: 0.7364 - val_loss: 0.5516\n",
      "Epoch 63/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7362 - loss: 0.5387 - val_accuracy: 0.7366 - val_loss: 0.5494\n",
      "Epoch 64/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7373 - loss: 0.5376 - val_accuracy: 0.7364 - val_loss: 0.5526\n",
      "Epoch 65/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7368 - loss: 0.5379 - val_accuracy: 0.7364 - val_loss: 0.5515\n",
      "Epoch 66/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7383 - loss: 0.5376 - val_accuracy: 0.7361 - val_loss: 0.5517\n",
      "Epoch 67/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7383 - loss: 0.5375 - val_accuracy: 0.7361 - val_loss: 0.5541\n",
      "Epoch 68/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7372 - loss: 0.5384 - val_accuracy: 0.7347 - val_loss: 0.5526\n",
      "Epoch 69/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7368 - loss: 0.5398 - val_accuracy: 0.7357 - val_loss: 0.5527\n",
      "Epoch 70/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7394 - loss: 0.5383 - val_accuracy: 0.7361 - val_loss: 0.5529\n",
      "Epoch 71/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7374 - loss: 0.5362 - val_accuracy: 0.7362 - val_loss: 0.5547\n",
      "Epoch 72/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7385 - loss: 0.5380 - val_accuracy: 0.7368 - val_loss: 0.5541\n",
      "Epoch 73/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7367 - loss: 0.5378 - val_accuracy: 0.7376 - val_loss: 0.5551\n",
      "Epoch 74/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7391 - loss: 0.5368 - val_accuracy: 0.7366 - val_loss: 0.5544\n",
      "Epoch 75/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7362 - loss: 0.5380 - val_accuracy: 0.7368 - val_loss: 0.5548\n",
      "Epoch 76/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7364 - loss: 0.5387 - val_accuracy: 0.7361 - val_loss: 0.5568\n",
      "Epoch 77/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7384 - loss: 0.5359 - val_accuracy: 0.7357 - val_loss: 0.5559\n",
      "Epoch 78/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7387 - loss: 0.5372 - val_accuracy: 0.7359 - val_loss: 0.5566\n",
      "Epoch 79/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7379 - loss: 0.5364 - val_accuracy: 0.7366 - val_loss: 0.5528\n",
      "Epoch 80/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7378 - loss: 0.5369 - val_accuracy: 0.7362 - val_loss: 0.5530\n",
      "Epoch 81/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7375 - loss: 0.5378 - val_accuracy: 0.7364 - val_loss: 0.5633\n",
      "Epoch 82/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7358 - loss: 0.5371 - val_accuracy: 0.7351 - val_loss: 0.5591\n",
      "Epoch 83/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7375 - loss: 0.5367 - val_accuracy: 0.7353 - val_loss: 0.5585\n",
      "Epoch 84/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7376 - loss: 0.5363 - val_accuracy: 0.7359 - val_loss: 0.5574\n",
      "Epoch 85/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7387 - loss: 0.5361 - val_accuracy: 0.7361 - val_loss: 0.5578\n",
      "Epoch 86/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7399 - loss: 0.5370 - val_accuracy: 0.7362 - val_loss: 0.5565\n",
      "Epoch 87/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7377 - loss: 0.5373 - val_accuracy: 0.7320 - val_loss: 0.5543\n",
      "Epoch 88/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7349 - loss: 0.5366 - val_accuracy: 0.7355 - val_loss: 0.5611\n",
      "Epoch 89/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7371 - loss: 0.5365 - val_accuracy: 0.7362 - val_loss: 0.5602\n",
      "Epoch 90/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7385 - loss: 0.5361 - val_accuracy: 0.7355 - val_loss: 0.5584\n",
      "Epoch 91/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7382 - loss: 0.5363 - val_accuracy: 0.7364 - val_loss: 0.5617\n",
      "Epoch 92/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7373 - loss: 0.5373 - val_accuracy: 0.7386 - val_loss: 0.5566\n",
      "Epoch 93/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7368 - loss: 0.5352 - val_accuracy: 0.7361 - val_loss: 0.5621\n",
      "Epoch 94/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.7357 - loss: 0.5371 - val_accuracy: 0.7372 - val_loss: 0.5634\n",
      "Epoch 95/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7375 - loss: 0.5375 - val_accuracy: 0.7374 - val_loss: 0.5572\n",
      "Epoch 96/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.7383 - loss: 0.5375 - val_accuracy: 0.7364 - val_loss: 0.5622\n",
      "Epoch 97/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7356 - loss: 0.5362 - val_accuracy: 0.7351 - val_loss: 0.5639\n",
      "Epoch 98/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7350 - loss: 0.5364 - val_accuracy: 0.7355 - val_loss: 0.5593\n",
      "Epoch 99/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7350 - loss: 0.5361 - val_accuracy: 0.7368 - val_loss: 0.5592\n",
      "Epoch 100/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7374 - loss: 0.5362 - val_accuracy: 0.7357 - val_loss: 0.5615\n",
      "Epoch 101/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7392 - loss: 0.5340 - val_accuracy: 0.7366 - val_loss: 0.5564\n",
      "Epoch 102/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7378 - loss: 0.5355 - val_accuracy: 0.7359 - val_loss: 0.5603\n",
      "Epoch 103/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7377 - loss: 0.5370 - val_accuracy: 0.7357 - val_loss: 0.5672\n",
      "Epoch 104/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7387 - loss: 0.5366 - val_accuracy: 0.7384 - val_loss: 0.5593\n",
      "Epoch 105/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7378 - loss: 0.5359 - val_accuracy: 0.7376 - val_loss: 0.5593\n",
      "Epoch 106/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7388 - loss: 0.5344 - val_accuracy: 0.7355 - val_loss: 0.5585\n",
      "Epoch 107/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7375 - loss: 0.5366 - val_accuracy: 0.7366 - val_loss: 0.5604\n",
      "Epoch 108/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7371 - loss: 0.5354 - val_accuracy: 0.7372 - val_loss: 0.5605\n",
      "Epoch 109/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7377 - loss: 0.5364 - val_accuracy: 0.7370 - val_loss: 0.5657\n",
      "Epoch 110/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7372 - loss: 0.5355 - val_accuracy: 0.7374 - val_loss: 0.5610\n",
      "Epoch 111/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7377 - loss: 0.5341 - val_accuracy: 0.7361 - val_loss: 0.5641\n",
      "Epoch 112/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7377 - loss: 0.5359 - val_accuracy: 0.7378 - val_loss: 0.5655\n",
      "Epoch 113/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7387 - loss: 0.5357 - val_accuracy: 0.7378 - val_loss: 0.5622\n",
      "Epoch 114/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7359 - loss: 0.5353 - val_accuracy: 0.7372 - val_loss: 0.5586\n",
      "Epoch 115/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7373 - loss: 0.5369 - val_accuracy: 0.7359 - val_loss: 0.5591\n",
      "Epoch 116/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7378 - loss: 0.5343 - val_accuracy: 0.7361 - val_loss: 0.5613\n",
      "Epoch 117/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7373 - loss: 0.5343 - val_accuracy: 0.7380 - val_loss: 0.5604\n",
      "Epoch 118/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7367 - loss: 0.5344 - val_accuracy: 0.7370 - val_loss: 0.5666\n",
      "Epoch 119/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7372 - loss: 0.5346 - val_accuracy: 0.7388 - val_loss: 0.5613\n",
      "Epoch 120/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7386 - loss: 0.5344 - val_accuracy: 0.7376 - val_loss: 0.5663\n",
      "Epoch 121/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7367 - loss: 0.5347 - val_accuracy: 0.7378 - val_loss: 0.5703\n",
      "Epoch 122/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7387 - loss: 0.5342 - val_accuracy: 0.7372 - val_loss: 0.5665\n",
      "Epoch 123/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7383 - loss: 0.5346 - val_accuracy: 0.7368 - val_loss: 0.5661\n",
      "Epoch 124/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7385 - loss: 0.5343 - val_accuracy: 0.7368 - val_loss: 0.5697\n",
      "Epoch 125/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7375 - loss: 0.5348 - val_accuracy: 0.7380 - val_loss: 0.5644\n",
      "Epoch 126/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7369 - loss: 0.5336 - val_accuracy: 0.7378 - val_loss: 0.5721\n",
      "Epoch 127/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7373 - loss: 0.5370 - val_accuracy: 0.7380 - val_loss: 0.5679\n",
      "Epoch 128/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7379 - loss: 0.5344 - val_accuracy: 0.7372 - val_loss: 0.5673\n",
      "Epoch 129/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7381 - loss: 0.5342 - val_accuracy: 0.7362 - val_loss: 0.5728\n",
      "Epoch 130/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7380 - loss: 0.5342 - val_accuracy: 0.7362 - val_loss: 0.5723\n",
      "Epoch 131/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7379 - loss: 0.5345 - val_accuracy: 0.7368 - val_loss: 0.5668\n",
      "Epoch 132/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7369 - loss: 0.5344 - val_accuracy: 0.7349 - val_loss: 0.5659\n",
      "Epoch 133/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7374 - loss: 0.5336 - val_accuracy: 0.7345 - val_loss: 0.5737\n",
      "Epoch 134/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7381 - loss: 0.5349 - val_accuracy: 0.7339 - val_loss: 0.5719\n",
      "Epoch 135/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7362 - loss: 0.5334 - val_accuracy: 0.7341 - val_loss: 0.5677\n",
      "Epoch 136/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7371 - loss: 0.5325 - val_accuracy: 0.7357 - val_loss: 0.5688\n",
      "Epoch 137/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7365 - loss: 0.5339 - val_accuracy: 0.7355 - val_loss: 0.5660\n",
      "Epoch 138/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7378 - loss: 0.5333 - val_accuracy: 0.7370 - val_loss: 0.5674\n",
      "Epoch 139/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7367 - loss: 0.5350 - val_accuracy: 0.7378 - val_loss: 0.5726\n",
      "Epoch 140/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7368 - loss: 0.5346 - val_accuracy: 0.7370 - val_loss: 0.5678\n",
      "Epoch 141/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7370 - loss: 0.5334 - val_accuracy: 0.7359 - val_loss: 0.5794\n",
      "Epoch 142/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7376 - loss: 0.5344 - val_accuracy: 0.7362 - val_loss: 0.5638\n",
      "Epoch 143/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7370 - loss: 0.5336 - val_accuracy: 0.7357 - val_loss: 0.5755\n",
      "Epoch 144/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7368 - loss: 0.5336 - val_accuracy: 0.7347 - val_loss: 0.5744\n",
      "Epoch 145/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7371 - loss: 0.5328 - val_accuracy: 0.7347 - val_loss: 0.5729\n",
      "Epoch 146/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7370 - loss: 0.5342 - val_accuracy: 0.7351 - val_loss: 0.5765\n",
      "Epoch 147/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7379 - loss: 0.5346 - val_accuracy: 0.7359 - val_loss: 0.5721\n",
      "Epoch 148/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7382 - loss: 0.5328 - val_accuracy: 0.7362 - val_loss: 0.5754\n",
      "Epoch 149/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7379 - loss: 0.5342 - val_accuracy: 0.7351 - val_loss: 0.5788\n",
      "Epoch 150/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7368 - loss: 0.5346 - val_accuracy: 0.7337 - val_loss: 0.5775\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=150, batch_size=32, verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 264us/step - accuracy: 0.7261 - loss: 0.5941\n",
      "Loss: 0.5941178202629089, Accuracy: 0.726064145565033\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Third Attempt Analysis**\n",
    "\n",
    "**Architecture:**\n",
    "\n",
    "Input Features: 43 (including all numeric and one-hot encoded categorical variables).\n",
    "Hidden Layers:\n",
    "Layer 1: 100 neurons with ReLU activation.\n",
    "Layer 2: 50 neurons with ReLU activation.\n",
    "Layer 3: 30 neurons with ReLU activation.\n",
    "Layer 4: 15 neurons with ReLU activation.\n",
    "Dropout Layer: Regularization with a rate of 0.1 to mitigate overfitting.\n",
    "Output Layer: 1 neuron with sigmoid activation (for binary classification).\n",
    "\n",
    "**Results:**\n",
    "\n",
    "Accuracy: 72.61%\n",
    "Loss: 0.5941\n",
    "\n",
    "**Key Observations:**\n",
    "\n",
    "The accuracy decreased slightly from the second attempt (72.90% to 72.61%), despite the added complexity of the architecture.\n",
    "The loss increased to 0.5941, which could indicate that the added layers and neurons introduced overfitting or increased noise in the model.\n",
    "The dropout rate (0.1) might not have been sufficient to counteract overfitting with this more complex architecture.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Consider adjusting the dropout rate to 0.2 or higher to better manage overfitting in this deeper architecture.\n",
    "Explore advanced regularization methods, such as L2 regularization, to stabilize training.\n",
    "Fine-tune hyperparameters like the learning rate or batch size to improve model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"H5/AlphabetSoupCharity_Attempt_3.h5\")\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">820</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │         \u001b[38;5;34m5,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m9,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m3,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m820\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,041</span> (74.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,041\u001b[0m (74.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,041</span> (74.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,041\u001b[0m (74.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fourth Attempt - Adjusting neurons without adding layers (updated with regularization and tuned learning rate)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Define the model\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# Input layer and first hidden layer with L2 regularization\n",
    "nn.add(tf.keras.layers.Dense(units=120, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Second hidden layer with L2 regularization\n",
    "nn.add(tf.keras.layers.Dense(units=80, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Third hidden layer with L2 regularization\n",
    "nn.add(tf.keras.layers.Dense(units=40, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Fourth hidden layer with L2 regularization\n",
    "nn.add(tf.keras.layers.Dense(units=20, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Dropout layer with a rate of 0.2\n",
    "nn.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">820</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │         \u001b[38;5;34m5,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m9,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m3,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m820\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,041</span> (74.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,041\u001b[0m (74.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,041</span> (74.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,041\u001b[0m (74.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model with a tuned learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "nn.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524us/step - accuracy: 0.7019 - loss: 1.4914 - val_accuracy: 0.7293 - val_loss: 0.6173\n",
      "Epoch 2/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.7200 - loss: 0.6244 - val_accuracy: 0.7277 - val_loss: 0.6024\n",
      "Epoch 3/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7189 - loss: 0.6131 - val_accuracy: 0.7324 - val_loss: 0.5963\n",
      "Epoch 4/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.7206 - loss: 0.6079 - val_accuracy: 0.7347 - val_loss: 0.5925\n",
      "Epoch 5/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7220 - loss: 0.6055 - val_accuracy: 0.7275 - val_loss: 0.5919\n",
      "Epoch 6/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7213 - loss: 0.6026 - val_accuracy: 0.7337 - val_loss: 0.5891\n",
      "Epoch 7/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7238 - loss: 0.6018 - val_accuracy: 0.7337 - val_loss: 0.5885\n",
      "Epoch 8/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7239 - loss: 0.6009 - val_accuracy: 0.7339 - val_loss: 0.5874\n",
      "Epoch 9/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7207 - loss: 0.6012 - val_accuracy: 0.7283 - val_loss: 0.5883\n",
      "Epoch 10/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.7200 - loss: 0.5992 - val_accuracy: 0.7291 - val_loss: 0.5865\n",
      "Epoch 11/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7228 - loss: 0.5970 - val_accuracy: 0.7331 - val_loss: 0.5844\n",
      "Epoch 12/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7212 - loss: 0.5976 - val_accuracy: 0.7291 - val_loss: 0.5847\n",
      "Epoch 13/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7226 - loss: 0.5947 - val_accuracy: 0.7293 - val_loss: 0.5847\n",
      "Epoch 14/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7208 - loss: 0.5949 - val_accuracy: 0.7302 - val_loss: 0.5829\n",
      "Epoch 15/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7213 - loss: 0.5970 - val_accuracy: 0.7298 - val_loss: 0.5832\n",
      "Epoch 16/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.7197 - loss: 0.5945 - val_accuracy: 0.7304 - val_loss: 0.5822\n",
      "Epoch 17/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.7208 - loss: 0.5932 - val_accuracy: 0.7289 - val_loss: 0.5819\n",
      "Epoch 18/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7244 - loss: 0.5953 - val_accuracy: 0.7302 - val_loss: 0.5807\n",
      "Epoch 19/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7219 - loss: 0.5925 - val_accuracy: 0.7300 - val_loss: 0.5807\n",
      "Epoch 20/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7218 - loss: 0.5917 - val_accuracy: 0.7296 - val_loss: 0.5812\n",
      "Epoch 21/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7236 - loss: 0.5918 - val_accuracy: 0.7304 - val_loss: 0.5802\n",
      "Epoch 22/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7254 - loss: 0.5914 - val_accuracy: 0.7294 - val_loss: 0.5799\n",
      "Epoch 23/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7241 - loss: 0.5913 - val_accuracy: 0.7294 - val_loss: 0.5798\n",
      "Epoch 24/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.7228 - loss: 0.5906 - val_accuracy: 0.7294 - val_loss: 0.5793\n",
      "Epoch 25/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.7216 - loss: 0.5927 - val_accuracy: 0.7298 - val_loss: 0.5791\n",
      "Epoch 26/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7220 - loss: 0.5893 - val_accuracy: 0.7304 - val_loss: 0.5782\n",
      "Epoch 27/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.7215 - loss: 0.5900 - val_accuracy: 0.7298 - val_loss: 0.5787\n",
      "Epoch 28/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7235 - loss: 0.5888 - val_accuracy: 0.7300 - val_loss: 0.5779\n",
      "Epoch 29/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7248 - loss: 0.5897 - val_accuracy: 0.7300 - val_loss: 0.5776\n",
      "Epoch 30/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7246 - loss: 0.5902 - val_accuracy: 0.7294 - val_loss: 0.5782\n",
      "Epoch 31/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7231 - loss: 0.5911 - val_accuracy: 0.7306 - val_loss: 0.5775\n",
      "Epoch 32/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.7231 - loss: 0.5905 - val_accuracy: 0.7289 - val_loss: 0.5776\n",
      "Epoch 33/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7255 - loss: 0.5868 - val_accuracy: 0.7293 - val_loss: 0.5775\n",
      "Epoch 34/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.7240 - loss: 0.5891 - val_accuracy: 0.7298 - val_loss: 0.5777\n",
      "Epoch 35/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.7227 - loss: 0.5879 - val_accuracy: 0.7296 - val_loss: 0.5768\n",
      "Epoch 36/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7250 - loss: 0.5876 - val_accuracy: 0.7294 - val_loss: 0.5763\n",
      "Epoch 37/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.7234 - loss: 0.5875 - val_accuracy: 0.7308 - val_loss: 0.5766\n",
      "Epoch 38/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7226 - loss: 0.5873 - val_accuracy: 0.7291 - val_loss: 0.5760\n",
      "Epoch 39/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7245 - loss: 0.5879 - val_accuracy: 0.7291 - val_loss: 0.5765\n",
      "Epoch 40/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7230 - loss: 0.5870 - val_accuracy: 0.7300 - val_loss: 0.5756\n",
      "Epoch 41/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7248 - loss: 0.5871 - val_accuracy: 0.7308 - val_loss: 0.5770\n",
      "Epoch 42/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.7225 - loss: 0.5855 - val_accuracy: 0.7283 - val_loss: 0.5788\n",
      "Epoch 43/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.7228 - loss: 0.5861 - val_accuracy: 0.7300 - val_loss: 0.5751\n",
      "Epoch 44/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7242 - loss: 0.5872 - val_accuracy: 0.7285 - val_loss: 0.5764\n",
      "Epoch 45/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7230 - loss: 0.5864 - val_accuracy: 0.7306 - val_loss: 0.5753\n",
      "Epoch 46/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.7218 - loss: 0.5870 - val_accuracy: 0.7289 - val_loss: 0.5768\n",
      "Epoch 47/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7250 - loss: 0.5868 - val_accuracy: 0.7304 - val_loss: 0.5750\n",
      "Epoch 48/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7241 - loss: 0.5871 - val_accuracy: 0.7294 - val_loss: 0.5756\n",
      "Epoch 49/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7235 - loss: 0.5870 - val_accuracy: 0.7283 - val_loss: 0.5755\n",
      "Epoch 50/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7238 - loss: 0.5872 - val_accuracy: 0.7293 - val_loss: 0.5757\n",
      "Epoch 51/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.7218 - loss: 0.5863 - val_accuracy: 0.7298 - val_loss: 0.5752\n",
      "Epoch 52/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7225 - loss: 0.5847 - val_accuracy: 0.7285 - val_loss: 0.5749\n",
      "Epoch 53/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.7214 - loss: 0.5860 - val_accuracy: 0.7300 - val_loss: 0.5749\n",
      "Epoch 54/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.7256 - loss: 0.5855 - val_accuracy: 0.7300 - val_loss: 0.5743\n",
      "Epoch 55/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.7224 - loss: 0.5838 - val_accuracy: 0.7291 - val_loss: 0.5739\n",
      "Epoch 56/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.7253 - loss: 0.5857 - val_accuracy: 0.7289 - val_loss: 0.5741\n",
      "Epoch 57/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.7230 - loss: 0.5852 - val_accuracy: 0.7287 - val_loss: 0.5743\n",
      "Epoch 58/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.7224 - loss: 0.5854 - val_accuracy: 0.7296 - val_loss: 0.5746\n",
      "Epoch 59/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7246 - loss: 0.5859 - val_accuracy: 0.7287 - val_loss: 0.5736\n",
      "Epoch 60/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.7224 - loss: 0.5853 - val_accuracy: 0.7287 - val_loss: 0.5744\n",
      "Epoch 61/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7251 - loss: 0.5833 - val_accuracy: 0.7294 - val_loss: 0.5725\n",
      "Epoch 62/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.7225 - loss: 0.5846 - val_accuracy: 0.7302 - val_loss: 0.5735\n",
      "Epoch 63/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7257 - loss: 0.5844 - val_accuracy: 0.7293 - val_loss: 0.5734\n",
      "Epoch 64/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7248 - loss: 0.5854 - val_accuracy: 0.7283 - val_loss: 0.5747\n",
      "Epoch 65/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.7234 - loss: 0.5863 - val_accuracy: 0.7298 - val_loss: 0.5747\n",
      "Epoch 66/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7208 - loss: 0.5854 - val_accuracy: 0.7341 - val_loss: 0.5727\n",
      "Epoch 67/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7244 - loss: 0.5844 - val_accuracy: 0.7289 - val_loss: 0.5750\n",
      "Epoch 68/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.7244 - loss: 0.5850 - val_accuracy: 0.7345 - val_loss: 0.5728\n",
      "Epoch 69/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7244 - loss: 0.5846 - val_accuracy: 0.7300 - val_loss: 0.5746\n",
      "Epoch 70/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7259 - loss: 0.5839 - val_accuracy: 0.7300 - val_loss: 0.5738\n",
      "Epoch 71/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.7258 - loss: 0.5846 - val_accuracy: 0.7279 - val_loss: 0.5734\n",
      "Epoch 72/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7237 - loss: 0.5827 - val_accuracy: 0.7291 - val_loss: 0.5741\n",
      "Epoch 73/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7248 - loss: 0.5843 - val_accuracy: 0.7306 - val_loss: 0.5742\n",
      "Epoch 74/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7245 - loss: 0.5833 - val_accuracy: 0.7294 - val_loss: 0.5739\n",
      "Epoch 75/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7239 - loss: 0.5838 - val_accuracy: 0.7291 - val_loss: 0.5742\n",
      "Epoch 76/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7232 - loss: 0.5847 - val_accuracy: 0.7304 - val_loss: 0.5736\n",
      "Epoch 77/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7216 - loss: 0.5842 - val_accuracy: 0.7298 - val_loss: 0.5735\n",
      "Epoch 78/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7244 - loss: 0.5833 - val_accuracy: 0.7300 - val_loss: 0.5729\n",
      "Epoch 79/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.7252 - loss: 0.5837 - val_accuracy: 0.7306 - val_loss: 0.5732\n",
      "Epoch 80/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7235 - loss: 0.5845 - val_accuracy: 0.7296 - val_loss: 0.5724\n",
      "Epoch 81/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7253 - loss: 0.5827 - val_accuracy: 0.7291 - val_loss: 0.5735\n",
      "Epoch 82/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.7237 - loss: 0.5831 - val_accuracy: 0.7287 - val_loss: 0.5736\n",
      "Epoch 83/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7214 - loss: 0.5843 - val_accuracy: 0.7298 - val_loss: 0.5733\n",
      "Epoch 84/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7257 - loss: 0.5826 - val_accuracy: 0.7300 - val_loss: 0.5725\n",
      "Epoch 85/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7227 - loss: 0.5839 - val_accuracy: 0.7291 - val_loss: 0.5726\n",
      "Epoch 86/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7252 - loss: 0.5835 - val_accuracy: 0.7298 - val_loss: 0.5724\n",
      "Epoch 87/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.7237 - loss: 0.5829 - val_accuracy: 0.7294 - val_loss: 0.5736\n",
      "Epoch 88/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7247 - loss: 0.5832 - val_accuracy: 0.7306 - val_loss: 0.5727\n",
      "Epoch 89/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7231 - loss: 0.5821 - val_accuracy: 0.7306 - val_loss: 0.5720\n",
      "Epoch 90/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.7252 - loss: 0.5818 - val_accuracy: 0.7298 - val_loss: 0.5728\n",
      "Epoch 91/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7251 - loss: 0.5829 - val_accuracy: 0.7287 - val_loss: 0.5743\n",
      "Epoch 92/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7227 - loss: 0.5828 - val_accuracy: 0.7291 - val_loss: 0.5731\n",
      "Epoch 93/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7241 - loss: 0.5829 - val_accuracy: 0.7289 - val_loss: 0.5736\n",
      "Epoch 94/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7253 - loss: 0.5820 - val_accuracy: 0.7306 - val_loss: 0.5727\n",
      "Epoch 95/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.7256 - loss: 0.5831 - val_accuracy: 0.7298 - val_loss: 0.5726\n",
      "Epoch 96/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.7212 - loss: 0.5829 - val_accuracy: 0.7294 - val_loss: 0.5726\n",
      "Epoch 97/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7249 - loss: 0.5834 - val_accuracy: 0.7293 - val_loss: 0.5727\n",
      "Epoch 98/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.7218 - loss: 0.5821 - val_accuracy: 0.7285 - val_loss: 0.5725\n",
      "Epoch 99/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7269 - loss: 0.5817 - val_accuracy: 0.7287 - val_loss: 0.5726\n",
      "Epoch 100/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7255 - loss: 0.5828 - val_accuracy: 0.7287 - val_loss: 0.5719\n",
      "Epoch 101/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7250 - loss: 0.5826 - val_accuracy: 0.7289 - val_loss: 0.5735\n",
      "Epoch 102/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7254 - loss: 0.5837 - val_accuracy: 0.7285 - val_loss: 0.5713\n",
      "Epoch 103/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.7245 - loss: 0.5826 - val_accuracy: 0.7287 - val_loss: 0.5720\n",
      "Epoch 104/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7243 - loss: 0.5831 - val_accuracy: 0.7285 - val_loss: 0.5728\n",
      "Epoch 105/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.7266 - loss: 0.5824 - val_accuracy: 0.7291 - val_loss: 0.5721\n",
      "Epoch 106/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7258 - loss: 0.5816 - val_accuracy: 0.7285 - val_loss: 0.5726\n",
      "Epoch 107/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7215 - loss: 0.5822 - val_accuracy: 0.7294 - val_loss: 0.5723\n",
      "Epoch 108/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7223 - loss: 0.5843 - val_accuracy: 0.7293 - val_loss: 0.5720\n",
      "Epoch 109/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7239 - loss: 0.5838 - val_accuracy: 0.7287 - val_loss: 0.5713\n",
      "Epoch 110/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.7242 - loss: 0.5822 - val_accuracy: 0.7287 - val_loss: 0.5717\n",
      "Epoch 111/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7239 - loss: 0.5821 - val_accuracy: 0.7304 - val_loss: 0.5715\n",
      "Epoch 112/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7239 - loss: 0.5819 - val_accuracy: 0.7294 - val_loss: 0.5724\n",
      "Epoch 113/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7219 - loss: 0.5838 - val_accuracy: 0.7283 - val_loss: 0.5725\n",
      "Epoch 114/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7236 - loss: 0.5816 - val_accuracy: 0.7277 - val_loss: 0.5724\n",
      "Epoch 115/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7237 - loss: 0.5811 - val_accuracy: 0.7291 - val_loss: 0.5723\n",
      "Epoch 116/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.7254 - loss: 0.5810 - val_accuracy: 0.7289 - val_loss: 0.5714\n",
      "Epoch 117/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7248 - loss: 0.5814 - val_accuracy: 0.7293 - val_loss: 0.5727\n",
      "Epoch 118/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7246 - loss: 0.5812 - val_accuracy: 0.7289 - val_loss: 0.5720\n",
      "Epoch 119/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7241 - loss: 0.5799 - val_accuracy: 0.7281 - val_loss: 0.5745\n",
      "Epoch 120/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.7251 - loss: 0.5810 - val_accuracy: 0.7289 - val_loss: 0.5724\n",
      "Epoch 121/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7257 - loss: 0.5819 - val_accuracy: 0.7289 - val_loss: 0.5721\n",
      "Epoch 122/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.7249 - loss: 0.5813 - val_accuracy: 0.7291 - val_loss: 0.5720\n",
      "Epoch 123/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7254 - loss: 0.5818 - val_accuracy: 0.7296 - val_loss: 0.5714\n",
      "Epoch 124/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7265 - loss: 0.5807 - val_accuracy: 0.7281 - val_loss: 0.5719\n",
      "Epoch 125/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7259 - loss: 0.5812 - val_accuracy: 0.7296 - val_loss: 0.5707\n",
      "Epoch 126/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7264 - loss: 0.5813 - val_accuracy: 0.7283 - val_loss: 0.5719\n",
      "Epoch 127/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7244 - loss: 0.5819 - val_accuracy: 0.7287 - val_loss: 0.5714\n",
      "Epoch 128/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7249 - loss: 0.5824 - val_accuracy: 0.7285 - val_loss: 0.5710\n",
      "Epoch 129/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7258 - loss: 0.5794 - val_accuracy: 0.7279 - val_loss: 0.5714\n",
      "Epoch 130/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7251 - loss: 0.5821 - val_accuracy: 0.7277 - val_loss: 0.5711\n",
      "Epoch 131/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7242 - loss: 0.5807 - val_accuracy: 0.7291 - val_loss: 0.5716\n",
      "Epoch 132/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7251 - loss: 0.5812 - val_accuracy: 0.7283 - val_loss: 0.5720\n",
      "Epoch 133/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7247 - loss: 0.5808 - val_accuracy: 0.7304 - val_loss: 0.5716\n",
      "Epoch 134/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7236 - loss: 0.5814 - val_accuracy: 0.7289 - val_loss: 0.5727\n",
      "Epoch 135/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7257 - loss: 0.5816 - val_accuracy: 0.7291 - val_loss: 0.5724\n",
      "Epoch 136/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7235 - loss: 0.5814 - val_accuracy: 0.7293 - val_loss: 0.5708\n",
      "Epoch 137/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7259 - loss: 0.5815 - val_accuracy: 0.7281 - val_loss: 0.5706\n",
      "Epoch 138/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7239 - loss: 0.5809 - val_accuracy: 0.7329 - val_loss: 0.5710\n",
      "Epoch 139/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.7253 - loss: 0.5811 - val_accuracy: 0.7285 - val_loss: 0.5725\n",
      "Epoch 140/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7252 - loss: 0.5820 - val_accuracy: 0.7291 - val_loss: 0.5715\n",
      "Epoch 141/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.7240 - loss: 0.5808 - val_accuracy: 0.7329 - val_loss: 0.5703\n",
      "Epoch 142/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7227 - loss: 0.5823 - val_accuracy: 0.7294 - val_loss: 0.5733\n",
      "Epoch 143/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7252 - loss: 0.5808 - val_accuracy: 0.7296 - val_loss: 0.5741\n",
      "Epoch 144/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7269 - loss: 0.5794 - val_accuracy: 0.7291 - val_loss: 0.5713\n",
      "Epoch 145/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7240 - loss: 0.5809 - val_accuracy: 0.7289 - val_loss: 0.5710\n",
      "Epoch 146/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7261 - loss: 0.5810 - val_accuracy: 0.7293 - val_loss: 0.5724\n",
      "Epoch 147/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7245 - loss: 0.5817 - val_accuracy: 0.7293 - val_loss: 0.5728\n",
      "Epoch 148/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.7227 - loss: 0.5821 - val_accuracy: 0.7287 - val_loss: 0.5712\n",
      "Epoch 149/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7249 - loss: 0.5813 - val_accuracy: 0.7289 - val_loss: 0.5706\n",
      "Epoch 150/150\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7245 - loss: 0.5792 - val_accuracy: 0.7281 - val_loss: 0.5726\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=150, batch_size=32, verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 283us/step - accuracy: 0.7208 - loss: 0.5792\n",
      "Loss: 0.5791938304901123, Accuracy: 0.7208163142204285\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourth Attempt Analysis**\n",
    "\n",
    "**Architecture:**\n",
    "\n",
    "Input Features: 43 (including all numeric and one-hot encoded categorical variables).\n",
    "Hidden Layers:\n",
    "Layer 1: 120 neurons with ReLU activation and L2 regularization.\n",
    "Layer 2: 80 neurons with ReLU activation and L2 regularization.\n",
    "Layer 3: 40 neurons with ReLU activation and L2 regularization.\n",
    "Layer 4: 20 neurons with ReLU activation and L2 regularization.\n",
    "Dropout Layer: Regularization with a rate of 0.2 to prevent overfitting.\n",
    "Output Layer: 1 neuron with sigmoid activation (for binary classification).\n",
    "\n",
    "**Results:**\n",
    "\n",
    "Accuracy: 72.08%\n",
    "Loss: 0.5792\n",
    "\n",
    "**Key Observations:**\n",
    "\n",
    "The accuracy decreased slightly compared to earlier attempts (72.90% in the second attempt and 72.61% in the third attempt).\n",
    "The loss remained relatively stable, indicating the model is making consistent predictions.\n",
    "Adding L2 regularization and increasing the dropout rate did not yield significant improvements, suggesting the architecture may be too complex for the current dataset.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Simplify the architecture by reducing the number of neurons or layers to avoid overfitting and excess noise.\n",
    "Experiment with a higher dropout rate (e.g., 0.3) to test for improved generalization.\n",
    "Consider switching to alternative models, such as Random Forests or XGBoost, which may handle the dataset more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"H5/AlphabetSoupCharity_Attempt_4.h5\")\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Results from all attempts\n",
    "attempts = [\"Attempt 1\", \"Attempt 2\", \"Attempt 3\", \"Attempt 4\"]\n",
    "accuracies = [72.65, 72.90, 72.61, 72.08]\n",
    "losses = [0.5560, 0.5733, 0.5941, 0.5792]\n",
    "\n",
    "# Cell 1: Plot accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(attempts, accuracies, marker='o', label=\"Accuracy (%)\")\n",
    "plt.title(\"Accuracy Across Attempts\")\n",
    "plt.xlabel(\"Attempts\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(\"accuracy_plot.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 2: Plot loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(attempts, losses, marker='o', label=\"Loss\")\n",
    "plt.title(\"Loss Across Attempts\")\n",
    "plt.xlabel(\"Attempts\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(\"loss_plot.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
